{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from keras import Sequential\n",
    "from keras import datasets\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from time import time\n",
    "from time import sleep\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "folder = \"/home/strahinja/Desktop/valjda_kraj/new_kraj/dataset_filtered/\"\n",
    "\n",
    "onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "files = []\n",
    "y = []\n",
    "i=0\n",
    "for _file in onlyfiles:\n",
    "    files.append(_file)\n",
    "    label_in_file = _file.rfind(\"_\")\n",
    "    label_in_file = label_in_file + 1\n",
    "    y.append(int(_file[label_in_file:label_in_file + 1]))\n",
    "\n",
    "image_size = 30\n",
    "\n",
    "x = np.ndarray(shape=(len(files), image_size, image_size),\n",
    "                     dtype=int)\n",
    "\n",
    "i = 0\n",
    "for _file in files:\n",
    "    img = load_img(folder + \"/\" + _file)\n",
    "    img.thumbnail((image_size, image_size))\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape(image_size, image_size, 3)\n",
    "    img = np.mean(img, axis = 2)\n",
    "    x[i] = img\n",
    "    i += 1\n",
    "    \n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('dataset_x', x)\n",
    "# np.save('dataset_y', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.load('new_dataset_x.npy')\n",
    "# y = np.load('new_dataset_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[26])\n",
    "print(y[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size = 0.33, random_state = 7, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 30\n",
    "network = Sequential()\n",
    "network.add(Conv2D(input_shape=(image_size, image_size, 1), filters=32, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "network.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "network.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "network.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "network.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "network.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "network.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "network.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "network.add(Flatten())\n",
    "network.add(Dense(units=32, activation='relu'))\n",
    "network.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='adam', loss = losses.categorical_crossentropy, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12180, 30, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12180, 30, 30, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train[0].shape[0], x_train[0].shape[0], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test[0].shape[0], x_test[0].shape[0], 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './checkpoints/chekpoint' + \"-final-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='acc', min_delta=0, patience=3, mode='auto'),\n",
    "    ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8526 samples, validate on 3654 samples\n",
      "Epoch 1/30\n",
      "8526/8526 [==============================] - 19s 2ms/step - loss: 0.1059 - acc: 0.9710 - val_loss: 2.2621e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00000, saving model to ./checkpoints/chekpoint-final-01-1.00.hdf5\n",
      "Epoch 2/30\n",
      "8526/8526 [==============================] - 19s 2ms/step - loss: 1.7132e-06 - acc: 1.0000 - val_loss: 9.9665e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/chekpoint-final-02-1.00.hdf5\n",
      "Epoch 3/30\n",
      "8526/8526 [==============================] - 19s 2ms/step - loss: 9.0863e-07 - acc: 1.0000 - val_loss: 6.5168e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/chekpoint-final-03-1.00.hdf5\n",
      "Epoch 4/30\n",
      "8526/8526 [==============================] - 19s 2ms/step - loss: 6.1541e-07 - acc: 1.0000 - val_loss: 4.7565e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/chekpoint-final-04-1.00.hdf5\n",
      "Epoch 5/30\n",
      "8526/8526 [==============================] - 19s 2ms/step - loss: 4.6671e-07 - acc: 1.0000 - val_loss: 3.8685e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/chekpoint-final-05-1.00.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(x_train, y_train, batch_size=64, epochs=30, verbose=1, callbacks=callbacks, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 4s 623us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.006674403171928e-07, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.reshape(x.shape[0], x[0].shape[0], x[0].shape[0], 1)\n",
    "# y = to_categorical(y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = network.fit(x, y, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.save('/home/strahinja/Desktop/valjda_kraj/new_kraj/neural_filtered.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
